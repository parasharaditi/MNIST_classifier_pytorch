{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=datasets.MNIST(\"\",train=True, download=True,transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test=datasets.MNIST(\"\",train=False, download=True,transform=transforms.Compose([transforms.ToTensor()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=torch.utils.data.DataLoader(train,batch_size=10,shuffle=True)\n",
    "testset=torch.utils.data.DataLoader(test,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([5, 3, 1, 2, 9, 4, 5, 7, 1, 2])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0][0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "counter={0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
    "for data in trainset:\n",
    "    xs,ys=data\n",
    "    for yc in ys:\n",
    "        counter[int(yc)] +=1\n",
    "        \n",
    "        \n",
    "        \n",
    "print(counter)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(28*28,64)\n",
    "        self.fc2=nn.Linear(64,64)\n",
    "        self.fc3=nn.Linear(64,64)\n",
    "        self.fc4=nn.Linear(64,10)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=fnn.relu(self.fc1(x))\n",
    "        x=fnn.relu(self.fc2(x))\n",
    "        x=fnn.relu(self.fc3(x))\n",
    "        x=self.fc4(x)\n",
    "        return fnn.log_softmax(x,dim=1)\n",
    "        \n",
    "net=Net()\n",
    "print(net)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.rand((28,28))\n",
    "X=X.view(1,28*28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3283, -2.1291, -2.2861, -2.3747, -2.2759, -2.2892, -2.3978, -2.3568,\n",
       "         -2.2572, -2.3585]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0082, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0992, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0393, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "EPOCHS=4\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        X,y=data\n",
    "        net.zero_grad()\n",
    "        output=net(X.view(-1,28*28))\n",
    "        loss=fnn.nll_loss(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "total=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X,y=data\n",
    "        output=net(X.view(-1,28*28))\n",
    "        for idx,i in enumerate(output):\n",
    "            if torch.argmax(i)== y[idx]:\n",
    "                correct+=1\n",
    "            total+=1   \n",
    "            \n",
    "            \n",
    "print(\"Accuracy:\",round(correct/total,4))           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
